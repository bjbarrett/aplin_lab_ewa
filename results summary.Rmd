---
title: "03_results summary"
author: "Julia Penndorf & Brendan Barrett & Lucy Aplin"
date: "9/23/2021"
output: html_document
---

```{r setup, include=TRUE}
knitr::opts_chunk$set(echo = TRUE)
library(rethinking)
library(rstan)
```

# Overview
We fit 6 EWA models to start with. In this instance it was from the 60s window only foir the BA group. 
Social learning could not occur on the first timestep, and $A_{t,k}=0$.
A global model has yet to be fit.
Now lets load files.
```{r load rds and script , echo=FALSE}
source("02_01_plot_fcns.R")
readRDS("fit_i_60s.rds")
d <- read.csv("cockatoo_data/BA_Almonds_cockatoo_60s.csv")
d <- d[with(d, order(subject_index,date, rel_time)), ]

d$bout <- rep(0,nrow(d))
ff <- rep(0,length(unique(d$subject)))
for (r in 1:nrow(d)) {
  for(i in 1:length(unique(d$subject_index))) {
    if( d[r,"subject_index"]==i){ #this is temporary due to zeros
      ff[i] <-ff[i] + 1
      d$bout[r] <- ff[i]
    }
  }
}

d$tech_index <- as.integer(as.factor(d$behav1))
```
## Info Criteria
First we can look at WAIC scores, although these should not be treated religiously.
They can give us an overall understanding of variation in the models in predicting the data while penalizing overfitting.But there are caveats with information criteria and time series models.
```{r info criteria , eval=FALSE}
#ic_tab <- compare(fit_i , fit_freq, fit_male , fit_adult , fit_roost , fit_rank)
#ic_tab
```

I think this is in part because individuals are so successful, about `r mean(d$open)` on average, there are only 2 behaviors, and there is not huge heterogenity among individuals in behavior. 
At the end of this doc, I will plot all individual level predictions from all models to show this.

# Individual Learning
```{r il , eval=TRUE}
ls()
# precis(fit_i , pars=c('lambda' , 'phi' , 'sigma_i') , depth=2)
# precis(fit_i , pars=c('Rho_i') , depth=3)
post_ind <- extract(fit_i)
```
```{r il plots}
DensLambda(post_ind)
DensPhi(post_ind)
```